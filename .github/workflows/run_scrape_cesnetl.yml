name: Run Scraping CESNET-L Script

on:
  schedule:
    - cron: '0 3 * * 1' # Every Monday at 3am UTC
    - cron: '0 3 * * 3' # Every Wednesday at 3am UTC
    - cron: '0 3 * * 5' # Every Friday at 3am UTC
  workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Sparse-checkout shared-scripts into a subdirectory
      run: |
        # Create a directory for shared scripts and initialize it as a Git repo
        mkdir shared_scripts
        cd shared_scripts
        git init

        # Add the shared-scripts repository as a remote
        git remote add origin https://github.com/counseloreducationdata/shared_scripts.git

        # Enable sparse-checkout
        git config core.sparseCheckout true

        # Specify the files to include in sparse-checkout, pulling them into the shared_scripts directory
        echo "scraper.py" >> .git/info/sparse-checkout
        echo "text_extractor.py" >> .git/info/sparse-checkout
        echo "url_extractor.py" >> .git/info/sparse-checkout
        echo "salary_functions.py" >> .git/info/sparse-checkout

        # Pull only the specified files from the main branch
        git pull origin main
      shell: bash

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10.14' # same as local machine

    - name: Install dependencies
      run: pip install -r requirements.txt

    - name: Run script
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
        USERNAME: ${{ secrets.USERNAME }}
        PASSWORD: ${{ secrets.PASSWORD }}
      run: |
        python scrape_cesnetl.py
